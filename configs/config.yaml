run_mode: 'train_rl' #train_evo / train_rl / run_env

general:
  seed: 46

env:
  name: 'GridWorldEnv'
  parameters:
    rows: 4
    cols: 4
    max_steps: 100
#  name: 'TrackRunnerEnv'
#  parameters:
#    run_velocity: 0.015
#    turn_degrees: 15
#    track: 'F:\My Documents\Study\Programming\PycharmProjects\Reinforcement-Learning\src\Envs\Tracks\tracky.pkl'
#    max_steps: 300

model:
  hidden_layers_dims: [ 50 ,20]
  save_file: ~

train_evo:
  specimen_count: 200
  survivor_count: 20
  max_iterations: 20
  mutation_rate: 0.0001
  generation_method: "Random Splice"
  fitness_target: 0
  output_dir: 'F:\My Documents\Study\Programming\PycharmProjects\Reinforcement-Learning\output\evo_agents'

train_rl:
  reward_discount: 0.95
  epsilon: 0.8
  epsilon_decay: 0.99
  batch_size: 32
  max_episodes: 5000
  model_learning_rate: 0.1
  printout_episodes: 50
  output_dir_path: 'F:\My Documents\Study\Programming\PycharmProjects\Reinforcement-Learning\output\rl_agents'

run_env:
  agent_weights_file_path: 'F:\My Documents\Study\Programming\PycharmProjects\Reinforcement-Learning\output\evo_agents\TrackRunnerEnv_2021_07_03-21_41\agent_parameters_7_fitness_-1_00.pkl'